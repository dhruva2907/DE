{
  "components": {
    "comp-train-sentiment-model": {
      "executorLabel": "exec-train-sentiment-model",
      "inputDefinitions": {
        "parameters": {
          "model_output_gcs": {
            "description": "GCS path where model should be saved",
            "parameterType": "STRING"
          },
          "raw_data_gcs": {
            "description": "GCS path to raw CSV data (gs://bucket/file.csv)",
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "accuracy": {
            "description": "Accuracy score of new model",
            "parameterType": "NUMBER_DOUBLE"
          },
          "deployed": {
            "description": "Whether new model was deployed (True/False)",
            "parameterType": "BOOLEAN"
          }
        }
      }
    }
  },
  "deploymentSpec": {
    "executors": {
      "exec-train-sentiment-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "train_sentiment_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.3.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'google-cloud-storage==2.10.0' 'pandas==2.0.3' 'scikit-learn==1.2.2' 'numpy==1.24.3' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef train_sentiment_model(\n    raw_data_gcs: str,\n    model_output_gcs: str\n) -> NamedTuple('Outputs', [('accuracy', float), ('deployed', bool)]):\n    \"\"\"\n    Train sentiment analysis model with champion/challenger comparison.\n\n    Args:\n        raw_data_gcs: GCS path to raw CSV data (gs://bucket/file.csv)\n        model_output_gcs: GCS path where model should be saved\n\n    Returns:\n        accuracy: Accuracy score of new model\n        deployed: Whether new model was deployed (True/False)\n    \"\"\"\n\n    # Import libraries (inside component)\n    import pandas as pd\n    import pickle\n    import re\n    from google.cloud import storage\n    from sklearn.feature_extraction.text import CountVectorizer\n    from sklearn.naive_bayes import MultinomialNB\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import accuracy_score\n    from collections import namedtuple\n\n\n    # STEP 1: Download Data from GCS\n    print(\"=\"*60)\n    print(\"STEP 1: Downloading data from GCS\")\n    print(\"=\"*60)\n\n    client = storage.Client()\n    bucket_name = raw_data_gcs.replace(\"gs://\", \"\").split(\"/\")[0]\n    blob_path = \"/\".join(raw_data_gcs.replace(\"gs://\", \"\").split(\"/\")[1:])\n\n    bucket = client.bucket(bucket_name)\n    blob = bucket.blob(blob_path)\n    blob.download_to_filename(\"/tmp/raw_data.csv\")\n\n    print(f\"\u2713 Downloaded from: {raw_data_gcs}\")\n\n\n    # STEP 2: Load and Validate Data\n\n    print(\"\\n\" + \"=\"*60)\n    print(\"STEP 2: Loading and validating data\")\n    print(\"=\"*60)\n\n    # Load with error handling for corrupted rows\n    try:\n        df = pd.read_csv(\"/tmp/raw_data.csv\", on_bad_lines='skip', nrows=2000)\n    except:\n        df = pd.read_csv(\"/tmp/raw_data.csv\", \n                        error_bad_lines=False, \n                        warn_bad_lines=False, \n                        nrows=2000)\n\n    print(f\"\u2713 Loaded {len(df)} rows\")\n    print(f\"\u2713 Columns: {list(df.columns)}\")\n\n\n    # STEP 3: Data Preprocessing\n\n    print(\"\\n\" + \"=\"*60)\n    print(\"STEP 3: Preprocessing data\")\n    print(\"=\"*60)\n\n    # Clean text: lowercase, remove special chars\n    df['clean_text'] = df['text'].astype(str).str.lower()\n    df['clean_text'] = df['clean_text'].str.replace('[^a-z ]', '', regex=True)\n\n    # Filter out very short text\n    df = df[df['clean_text'].str.len() > 10]\n\n    # Create binary labels (4+ stars = positive)\n    df['label'] = (df['rating'] >= 4).astype(int)\n\n    print(f\"\u2713 Cleaned text\")\n    print(f\"\u2713 Final dataset: {len(df)} rows\")\n    print(f\"\u2713 Positive samples: {df['label'].sum()}\")\n    print(f\"\u2713 Negative samples: {len(df) - df['label'].sum()}\")\n\n\n    # STEP 4: Feature Engineering\n\n    print(\"\\n\" + \"=\"*60)\n    print(\"STEP 4: Creating features\")\n    print(\"=\"*60)\n\n    # Create bag-of-words features\n    vectorizer = CountVectorizer(max_features=50, min_df=2)\n    X = vectorizer.fit_transform(df['clean_text'])\n    y = df['label'].values\n\n    print(f\"\u2713 Feature matrix shape: {X.shape}\")\n    print(f\"\u2713 Vocabulary size: {len(vectorizer.vocabulary_)}\")\n\n    # Train/test split\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42, stratify=y\n    )\n\n    print(f\"\u2713 Train samples: {X_train.shape[0]}\")\n    print(f\"\u2713 Test samples: {X_test.shape[0]}\")\n\n\n    # STEP 5: Train New Model\n\n    print(\"\\n\" + \"=\"*60)\n    print(\"STEP 5: Training new model\")\n    print(\"=\"*60)\n\n    # Train Naive Bayes classifier\n    new_model = MultinomialNB()\n    new_model.fit(X_train, y_train)\n\n    # Evaluate\n    y_pred = new_model.predict(X_test)\n    new_accuracy = accuracy_score(y_test, y_pred)\n\n    print(f\"\u2713 Model trained successfully\")\n    print(f\"\u2713 New model accuracy: {new_accuracy:.4f}\")\n\n\n    # STEP 6: Load Old Model (if exists)\n\n    print(\"\\n\" + \"=\"*60)\n    print(\"STEP 6: Checking for existing production model\")\n    print(\"=\"*60)\n\n    old_model_exists = False\n    old_accuracy = 0.0\n\n    try:\n        # Try to load existing model from GCS\n        model_bucket_name = model_output_gcs.replace(\"gs://\", \"\").split(\"/\")[0]\n        model_blob_path = \"/\".join(model_output_gcs.replace(\"gs://\", \"\").split(\"/\")[1:])\n\n        model_bucket = client.bucket(model_bucket_name)\n        model_blob = model_bucket.blob(model_blob_path)\n\n        if model_blob.exists():\n            print(\"\u2713 Found existing model in production\")\n            model_blob.download_to_filename(\"/tmp/old_model.pkl\")\n\n            with open(\"/tmp/old_model.pkl\", \"rb\") as f:\n                old_package = pickle.load(f)\n                old_accuracy = old_package.get('accuracy', 0.0)\n\n            print(f\"\u2713 Production model accuracy: {old_accuracy:.4f}\")\n            old_model_exists = True\n        else:\n            print(\"\u2713 No existing model found (first deployment)\")\n\n    except Exception as e:\n        print(f\"\u2713 No existing model found: {str(e)[:50]}\")\n\n\n    # STEP 7: Model Comparison & Deployment Decision\n\n    print(\"\\n\" + \"=\"*60)\n    print(\"STEP 7: Model comparison and deployment decision\")\n    print(\"=\"*60)\n\n    should_deploy = False\n    reason = \"\"\n\n    if not old_model_exists:\n        should_deploy = True\n        reason = \"No existing model - deploying baseline\"\n    elif new_accuracy > old_accuracy:\n        should_deploy = True\n        improvement = (new_accuracy - old_accuracy) * 100\n        reason = f\"New model is better (+{improvement:.2f}% improvement)\"\n    else:\n        should_deploy = False\n        decline = (old_accuracy - new_accuracy) * 100\n        reason = f\"Old model is better (-{decline:.2f}% decline)\"\n\n    print(f\"\\n{'='*60}\")\n    print(f\"COMPARISON RESULTS:\")\n    print(f\"  New Model Accuracy: {new_accuracy:.4f}\")\n    print(f\"  Old Model Accuracy: {old_accuracy:.4f}\")\n    print(f\"\\nDECISION: {'\u2713 DEPLOY NEW MODEL' if should_deploy else '\u2717 KEEP OLD MODEL'}\")\n    print(f\"REASON: {reason}\")\n    print(f\"{'='*60}\\n\")\n\n\n    # STEP 8: Save Model (if deployment approved)\n\n    if should_deploy:\n        print(\"=\"*60)\n        print(\"STEP 8: Deploying new model to production\")\n        print(\"=\"*60)\n\n        # Package model with metadata\n        model_package = {\n            'model': new_model,\n            'vectorizer': vectorizer,\n            'accuracy': float(new_accuracy),\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'samples_trained': int(X_train.shape[0]),\n            'features': int(X.shape[1])\n        }\n\n        # Save locally\n        with open(\"/tmp/model.pkl\", \"wb\") as f:\n            pickle.dump(model_package, f)\n\n        # Upload to GCS\n        model_bucket = client.bucket(model_bucket_name)\n        model_blob = model_bucket.blob(model_blob_path)\n        model_blob.upload_from_filename(\"/tmp/model.pkl\")\n\n        print(f\"\u2713 Model deployed to: {model_output_gcs}\")\n        print(f\"\u2713 Model accuracy: {new_accuracy:.4f}\")\n        print(f\"\u2713 Training samples: {X_train.shape[0]}\")\n\n    else:\n        print(\"=\"*60)\n        print(\"STEP 8: Keeping existing production model\")\n        print(\"=\"*60)\n        print(f\"\u2713 Production model unchanged\")\n        print(f\"\u2713 Current accuracy: {old_accuracy:.4f}\")\n\n\n    # PIPELINE COMPLETION\n\n    print(\"\\n\" + \"=\"*60)\n    print(\" PIPELINE EXECUTION COMPLETED SUCCESSFULLY\")\n    print(\"=\"*60)\n\n    # Return outputs\n    output = namedtuple('Outputs', ['accuracy', 'deployed'])\n    return output(new_accuracy, should_deploy)\n\n"
          ],
          "image": "python:3.10-slim"
        }
      }
    }
  },
  "pipelineInfo": {
    "description": "Continuous training pipeline for sentiment analysis with model comparison",
    "name": "sentiment-analysis-training-pipeline"
  },
  "root": {
    "dag": {
      "tasks": {
        "train-sentiment-model": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-train-sentiment-model"
          },
          "inputs": {
            "parameters": {
              "model_output_gcs": {
                "componentInputParameter": "model_output_gcs"
              },
              "raw_data_gcs": {
                "componentInputParameter": "raw_data_gcs"
              }
            }
          },
          "taskInfo": {
            "name": "train-sentiment-model"
          }
        }
      }
    },
    "inputDefinitions": {
      "parameters": {
        "model_output_gcs": {
          "defaultValue": "gs://model_mlops/sentiment_model.pickle",
          "description": "Path where trained model should be stored",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "raw_data_gcs": {
          "defaultValue": "gs://data_mlops/Movies_and_TV.csv",
          "description": "Path to raw data in GCS",
          "isOptional": true,
          "parameterType": "STRING"
        }
      }
    }
  },
  "schemaVersion": "2.1.0",
  "sdkVersion": "kfp-2.3.0"
}